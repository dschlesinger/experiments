{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "orf7QRr0vdOE",
        "pk6K_NMVOdR8",
        "zuIZnKFb7F7C",
        "KF_uEGy_zcYC",
        "kSMt2cS9Ks02"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyML6JLM9CDTTx7L/P29+sd9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dschlesinger/experiments/blob/main/pytorch_tutorial/PyTorch_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Expiriments with PyTorch\n",
        "\n",
        "### Sections\n",
        "\n",
        "- Setup\n",
        "- Compute\n",
        "- Tensors\n",
        "- Neural Networks\n"
      ],
      "metadata": {
        "id": "oAxC9KnAOSW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "orf7QRr0vdOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torch torchvision torchaudio torchmetrics tqdm # torch_xla\n",
        "%pip install datasets transformers # Hugging face"
      ],
      "metadata": {
        "collapsed": true,
        "id": "aJHYjrRE3QkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, datasets, transformers, numpy as np, matplotlib.pyplot as plt, PIL.Image as Image, requests, torchvision.transforms as transforms #, torch_xla, torch_xla.core.xla_model as xm\n",
        "\n",
        "from typing import *\n",
        "\n",
        "device = 'cpu'\n",
        "\n",
        "if torch.cuda.is_available(): device = 'cuda'"
      ],
      "metadata": {
        "id": "usLKTuaLOvaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "id": "in7lwJDG-P-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "\n",
        "class Color(Enum):\n",
        "  RED = '\\033[31m'\n",
        "  GREEN = '\\033[32m'\n",
        "  BLUE = '\\033[34m'\n",
        "  BLACK = '\\033[30m'\n",
        "  WHITE = '\\033[37m'\n",
        "  YELLOW = '\\033[33m'\n",
        "  RESET = '\\033[0m'\n",
        "\n",
        "  def apply(self, text: str) -> str:\n",
        "\n",
        "    return self.value + text + Color.RESET.value\n",
        "\n",
        "  def __call__(self, text: str) -> None:\n",
        "\n",
        "    print(self.value + text + Color.RESET.value)"
      ],
      "metadata": {
        "id": "T7KhfdfMvfc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_tpu() -> torch.device | None:\n",
        "  try:\n",
        "    tpu_device = xm.xla_device()\n",
        "    Color.GREEN(\"Found tpu\")\n",
        "    return tpu_device\n",
        "  except RuntimeError as RE:\n",
        "    Color.RED(\"Could not find tpu\")\n",
        "  return\n",
        "\n",
        "# device = load_tpu() or device"
      ],
      "metadata": {
        "id": "y8_ZP13G2iwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import repeat\n",
        "\n",
        "def fibbonaci(i: int) -> int:\n",
        "  \"\"\"Computes fibbonnaci with dynamic programming\n",
        "\n",
        "  Args:\n",
        "    i: int\n",
        "\n",
        "  Returns:\n",
        "    int: 0 if i <= 0 else fib(i)\n",
        "  \"\"\"\n",
        "\n",
        "  if i <= 0: return 0\n",
        "\n",
        "  # Start at step 1\n",
        "  window = [0, 1]\n",
        "\n",
        "  for _ in repeat(None, i - 1):\n",
        "\n",
        "    window = [window[1], window[0] + window[1]]\n",
        "\n",
        "  return window[1]"
      ],
      "metadata": {
        "id": "XtT3GktDeemH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing golden ratio\n",
        "\n",
        "t = 70\n",
        "\n",
        "error = []\n",
        "\n",
        "phi = (1 + (5 ** 0.5)) / 2\n",
        "\n",
        "func = lambda x: (((phi) ** x) - (1 - phi) ** x) / (5 ** 0.5)\n",
        "\n",
        "for i in range(t):\n",
        "\n",
        "  error.append(\n",
        "      func(i) - fibbonaci(i)\n",
        "  )\n",
        "\n",
        "plt.plot(range(t), error)"
      ],
      "metadata": {
        "id": "wsxaZ7QrpZnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute\n",
        "- CPU\n",
        "- Workers\n",
        "- GPU\n",
        "- TPU\n",
        "- Moving\n",
        "- Benchmarking"
      ],
      "metadata": {
        "id": "pk6K_NMVOdR8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CPU"
      ],
      "metadata": {
        "id": "Cn_okSFuTT4w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "912I5RVYOO9e"
      },
      "outputs": [],
      "source": [
        "# Find devices\n",
        "\n",
        "import psutil\n",
        "\n",
        "# Get CPU Stats\n",
        "\n",
        "ncpus: int = psutil.cpu_count(logical=False)\n",
        "nthreads: int = psutil.cpu_count(logical=True) # Same as torch.get_num_cpus()\n",
        "\n",
        "print(\n",
        "    f\"Num CPUS: {ncpus}\",\n",
        "    f\"Num Threads: {nthreads}\",\n",
        "    \"\",\n",
        "    sep='\\n'\n",
        ")\n",
        "\n",
        "# Control Torch CPU Acsess, test speed\n",
        "\n",
        "n: int = 5000\n",
        "\n",
        "print(\"Torch with 1 thread\")\n",
        "\n",
        "torch.set_num_threads(1)\n",
        "\n",
        "%time _ = torch.mm(torch.randn(n, n, device='cpu'), torch.randn(n, n, device='cpu'))\n",
        "\n",
        "print()\n",
        "\n",
        "print(f\"Torch with {nthreads} thread\")\n",
        "\n",
        "torch.set_num_threads(nthreads)\n",
        "\n",
        "%time _ = torch.mm(torch.randn(n, n, device='cpu'), torch.randn(n, n, device='cpu'))\n",
        "\n",
        "# Slightly slower as hyper threading and overhead"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Workers"
      ],
      "metadata": {
        "id": "mQncrodyTWU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For loading data in parallel\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "n: int = 1_000_000\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "\n",
        "    def __init__(self, n) -> None:\n",
        "\n",
        "      self.n = n\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return index  # Simulated data point\n",
        "    def __len__(self):\n",
        "        return self.n\n",
        "\n",
        "def worker_load_test(nworkers: int) -> None:\n",
        "  dataset = MyDataset(n)\n",
        "  dataloader = DataLoader(dataset, batch_size=32, num_workers=nworkers)\n",
        "\n",
        "  for batch in dataloader:\n",
        "      _ = batch\n",
        "\n",
        "# Test times\n",
        "\n",
        "for t in range(1, nthreads + 1):\n",
        "\n",
        "  print(f\"Using {t} threads\")\n",
        "\n",
        "  %time worker_load_test(t)\n",
        "\n",
        "  print()"
      ],
      "metadata": {
        "id": "TOw4hCVNTcz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU"
      ],
      "metadata": {
        "id": "5UQwttbNVI1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use GPU runtime\n",
        "\n",
        "found_gpu: bool = torch.cuda.is_available()\n",
        "\n",
        "ngpus: int = 0 if not found_gpu else torch.cuda.device_count()\n",
        "\n",
        "gpu_names: List[str] = [torch.cuda.get_device_name(i) for i in range(ngpus)]\n",
        "\n",
        "print(f\"Found GPU: {found_gpu}\",\n",
        "      f\"Num GPU: {ngpus}\",\n",
        "      \"\",\n",
        "      \"GPUs Found:\",\n",
        "      *[f'{name}' for name in gpu_names],\n",
        "      sep='\\n'\n",
        ")"
      ],
      "metadata": {
        "id": "0Ezm0TRgVNnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Runs nvidia-smi cmd continuously\n",
        "while True:\n",
        "    clear_output(wait=True)\n",
        "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
        "    print(result.stdout)\n",
        "    time.sleep(1)"
      ],
      "metadata": {
        "id": "BkX7VquGXlsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check memory usage before allocation\n",
        "print(\"Pre allocation\")\n",
        "print(f\"{torch.cuda.memory_allocated() / (8 * (1024)**2):.2f}MB\")\n",
        "print()\n",
        "\n",
        "# Allocate a large tensor\n",
        "a = torch.ones(size=(10000, 10000), device=device)\n",
        "\n",
        "# Check memory usage after allocation\n",
        "print(\"Post allocation\")\n",
        "print(f\"{torch.cuda.memory_allocated() / (8 * (1024)**2):.2f}MB\")\n",
        "print()\n",
        "\n",
        "# Clear the tensor and free memory\n",
        "del a\n",
        "\n",
        "import gc\n",
        "_ = gc.collect()\n",
        "\n",
        "# Check memory usage after deleting\n",
        "print(\"After deletion\")\n",
        "print(f\"{torch.cuda.memory_allocated() / (8 * (1024)**2):.2f}MB\")\n",
        "print()"
      ],
      "metadata": {
        "id": "qDsxH4LvyiMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TPU"
      ],
      "metadata": {
        "id": "gwRpS_hy3Dmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randint(low=-5, high=5, size=(1000, 1000), dtype=torch.float, device=tpu_device)\n",
        "b = torch.randint(low=-5, high=5, size=(1000, 1000), dtype=torch.float, device=tpu_device)\n",
        "\n",
        "# Tpus do lazy exectution this does not compute\n",
        "r = torch.matmul(a, b)\n",
        "\n",
        "print(\n",
        "    \"Result Shape: \",\n",
        "    r.shape,\n",
        "    \"\\n\",\n",
        "    \"Result Device: \",\n",
        "    r.device,\n",
        "    sep='',\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wWyAjK9P5elC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r # <-- Now it does as it prints"
      ],
      "metadata": {
        "id": "xAygUqJW1JzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Moving"
      ],
      "metadata": {
        "id": "dA7eAw8UXIy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make var on cpu\n",
        "A: torch.Tensor = torch.tensor([1,2,3], dtype=torch.int)\n",
        "\n",
        "print(\n",
        "    \"A is on the\",\n",
        "    A.device\n",
        ")\n",
        "\n",
        "# Make var on gpu\n",
        "\n",
        "B: torch.Tensor = torch.tensor([1,2,3], dtype=torch.int, device=device)\n",
        "\n",
        "print(\n",
        "    \"B is on the\",\n",
        "    B.device\n",
        ")\n",
        "\n",
        "# Doing opperations across devices\n",
        "try:\n",
        "  A + B\n",
        "except RuntimeError as RE:\n",
        "  Color.RED(\"Cannot do opperations across devices\")\n",
        "print()\n",
        "\n",
        "# Must transfer with .to()\n",
        "\n",
        "# to gpu\n",
        "print(\n",
        "    t := A.to(device) + B,\n",
        "    \"\\n\",\n",
        "    \"On: \",\n",
        "    t.device,\n",
        ")\n",
        "\n",
        "print()\n",
        "\n",
        "# to cpu\n",
        "print(\n",
        "    t := A + B.to('cpu'),\n",
        "    \"\\n\",\n",
        "    \"On: \",\n",
        "    t.device,\n",
        ")"
      ],
      "metadata": {
        "id": "Syj61sRuXLuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Benchmarking"
      ],
      "metadata": {
        "id": "7Yjp-qlE1YTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Benchmark matmul as dim scales (log)\n",
        "\n",
        "import timeit, random\n",
        "from IPython.display import clear_output\n",
        "\n",
        "n: int = 5\n",
        "\n",
        "tests = np.linspace(0, n, 100)\n",
        "cpu_times = np.zeros_like(tests)\n",
        "device_times = np.zeros_like(tests) # GPU or TPU\n",
        "\n",
        "for i, d in enumerate(tests):\n",
        "\n",
        "  clear_output(wait=True)\n",
        "  print(f\"{d}/{n}\")\n",
        "\n",
        "  a = torch.randint(low=-5, high=5, size=(int(10**d), int(10**d)), dtype=torch.float, device='cpu')\n",
        "  b = torch.randint(low=-5, high=5, size=(int(10**d), int(10**d)), dtype=torch.float, device='cpu')\n",
        "\n",
        "  # Excecute on cpu\n",
        "  cpu_times[i] = timeit.timeit(lambda: torch.matmul(a, b), number=1)\n",
        "\n",
        "  a = a.to(device)\n",
        "  b = b.to(device)\n",
        "\n",
        "  with open('log.txt', 'w') as logtxt:\n",
        "\n",
        "    device_times[i] = timeit.timeit(lambda: print(torch.matmul(a, b), file=logtxt), number=1)\n"
      ],
      "metadata": {
        "id": "jQG6zs4c1dM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "x - dim of mat log <br>\n",
        "y - seconds for matmul\n",
        "\n",
        "CPU vs GPU\n",
        "\n",
        "![CPU v GPU.png](data:image/png;base64,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)\n",
        "\n",
        "CPU vs TPU\n",
        "\n",
        "![cpu v tpu.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "s-QzFuWdpNEF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors\n",
        " - Basics\n",
        " - Math\n",
        " - Autograd"
      ],
      "metadata": {
        "id": "YHxNfHqp62ln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basics"
      ],
      "metadata": {
        "id": "zuIZnKFb7F7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating and Typing\n",
        "a: torch.Tensor = torch.tensor([1,2,3], dtype=torch.long)\n",
        "\n",
        "for x in filter(lambda x: callable(x), (getattr(torch, name) for name in dir(torch))):\n",
        "    continue\n",
        "\n",
        "    name = x.__name__\n",
        "    doc = x.__doc__\n",
        "    doc_summary = doc.__str__()[:50].replace(\"\\n\", \"\") if doc else None\n",
        "    print(f\"{name:<20}{doc_summary}\")\n",
        "\n",
        "# Function for creating tensors\n",
        "\n",
        "z = torch.zeros((2,2))\n",
        "\n",
        "o = torch.ones((2,2))\n",
        "\n",
        "f = torch.full((2,2), fill_value=3)\n",
        "\n",
        "i = torch.eye(2)\n",
        "\n",
        "# tensor with shape of other tensor\n",
        "\n",
        "z = torch.zeros_like(z)\n",
        "\n",
        "o = torch.ones_like(o)\n",
        "\n",
        "f = torch.full_like(f, fill_value=3)\n",
        "\n",
        "# Random\n",
        "\n",
        "r = torch.rand((2,2)) # [0, 1]\n",
        "\n",
        "rn = torch.randn((2,2)) # normal mean 0 std 1\n",
        "\n",
        "ri = torch.randint(size=(2,2), low=0, high=2) # uniform int [low, high)\n",
        "\n",
        "rp = torch.randperm(10) # for shuffling\n",
        "\n",
        "# Ranges\n",
        "\n",
        "ar = torch.arange(0, 10.5, 0.5)\n",
        "\n",
        "ls = torch.linspace(0, 10, 21)\n",
        "\n",
        "# Set seed for reproducability\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "print(torch.randint(0, 100, (1,)).item())\n",
        "print(torch.randint(0, 100, (1,)).item())\n",
        "\n",
        "# Create generator\n",
        "\n",
        "g = torch.Generator()\n",
        "\n",
        "g.manual_seed(24)\n",
        "\n",
        "print(torch.randint(0, 100, (1,), generator=g).item())\n",
        "print(torch.randint(0, 100, (1,), generator=g).item())"
      ],
      "metadata": {
        "id": "etvQJNEa85Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shaping and Slicing\n",
        "\n",
        "# Slicing\n",
        "at = torch.randint(size=(2,2,2), low=0, high=3)\n",
        "an = np.random.randint(size=(2,2,2), low=0, high=3)\n",
        "\n",
        "# Almost same as numpy : = all, -indexing\n",
        "at[:,:,:]\n",
        "an[:,:,:]\n",
        "\n",
        "# Diffrence is bool masking\n",
        "\n",
        "# Numpy\n",
        "mask = an > 1\n",
        "an[mask]\n",
        "\n",
        "# Torch\n",
        "mask = at > 1\n",
        "torch.masked_select(at, mask)\n",
        "\n",
        "# ? also support boolean indexing\n",
        "at[mask]\n",
        "\n",
        "# Shape\n",
        "b = torch.randint(size=(2,2,2), low=0, high=3)\n",
        "\n",
        "print(b.shape)\n",
        "print(b.stride())\n",
        "\n",
        "# Gets shape\n",
        "s = b.shape\n",
        "\n",
        "# Gets number of elements\n",
        "s.numel()\n",
        "\n",
        "# Gets stride, skips x to get next position in dim\n",
        "st = b.stride()\n",
        "\n",
        "# Reshape, ensure continguous\n",
        "b = b.reshape((-1,2,1))\n",
        "\n",
        "print(b.shape)\n",
        "print(b.stride())\n",
        "\n",
        "# Transpose\n",
        "b = b.transpose(0,1) # | .t() for 2D\n",
        "\n",
        "print(b.shape)\n",
        "print(b.stride())\n",
        "\n",
        "# Permute\n",
        "b = b.permute((1,0,2))\n",
        "\n",
        "print(b.shape)\n",
        "print(b.stride())\n",
        "\n",
        "# Add new dim, size 1\n",
        "b = b.unsqueeze(-1)\n",
        "\n",
        "# Remove new dim, size 1\n",
        "b = b.squeeze(-1)\n",
        "\n",
        "print(b.shape)\n",
        "print(b.stride())\n",
        "\n",
        "# Flatten\n",
        "\n",
        "b = b.flatten()\n",
        "\n",
        "print(b.shape)\n",
        "print(b.stride())\n",
        "\n",
        "pass"
      ],
      "metadata": {
        "id": "tRLVgGCQzmTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shaping part 2\n",
        "\n",
        "# Contiguous, each dim is in order in memory [[0,1], [2,3]] -> 0 1 2 3\n",
        "\n",
        "a = torch.randint(size=(2,2,2), low=0, high=3)\n",
        "\n",
        "print(\"A is contiguous\", a.is_contiguous())\n",
        "\n",
        "# if we use contiguous here just points as a is contiguous\n",
        "\n",
        "t = a.contiguous()\n",
        "\n",
        "print(\"T points to A\", id(a) == id(t))\n",
        "\n",
        "# Makes uncontigous\n",
        "b = a.permute((2,1,0))\n",
        "\n",
        "print(\"B is contiguous\", b.is_contiguous())\n",
        "\n",
        "print(\"B points to A\", id(a) == id(b))\n",
        "\n",
        "# Copies if not contigous\n",
        "c = b.contiguous()\n",
        "\n",
        "print(\"C is contiguous\", c.is_contiguous())\n",
        "\n",
        "print(\"C points to A\", id(a) == id(c))"
      ],
      "metadata": {
        "id": "uB9n0hs5ooWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape part 3, shapes with multiple tensors\n",
        "\n",
        "a = torch.randint(size=(3,3), low=0, high=5)\n",
        "b = torch.randint(size=(3,3), low=0, high=5)\n",
        "\n",
        "# Concatonate (along current dim) (k, n) (q, n) dim=0 -> (k+q, n)\n",
        "print(\n",
        "    f\".cat() ({a.shape}), ({b.shape}) -> {torch.cat([a, b], dim=0).shape}\\n\"\n",
        ")\n",
        "\n",
        "# Stack (create new dim) (m, (k, n)) dim=-1 -> (k, n, m)\n",
        "print(\n",
        "    f\".stack() ({a.shape}), ({b.shape}) -> {torch.stack([a, b], dim=-1).shape}\\n\"\n",
        ")\n",
        "\n",
        "# VStack (stack if dim < 2 else cat)\n",
        "print(\n",
        "    f\".vstack() ({a.shape}), ({b.shape}) -> {torch.vstack([a, b]).shape}\\n\"\n",
        ")\n",
        "\n",
        "# HStack (cat if dim < 2 else stack dim=1)\n",
        "print(\n",
        "    f\".hstack() ({a.shape}), ({b.shape}) -> {torch.hstack([a, b]).shape}\\n\"\n",
        ")\n",
        "\n",
        "# Split (n, m, k) 3: int -> (*(ceil(n/3) - 1, (3, m, k)), (1, (n % 3, m, k)) returns tuple\n",
        "print(\n",
        "    [x.shape for x in torch.split(a, 2)]\n",
        ")"
      ],
      "metadata": {
        "id": "VStxtn8FdAIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example with Image\n",
        "\n",
        "url = \"https://lp-cms-production.imgix.net/2024-04/GettyImages-143795695.jpg?auto=format,compress&q=72&fit=crop&w=1200\"\n",
        "\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "x = transforms.ToTensor()(image).permute((1,2,0)).contiguous() # Permute as image is 3, x, y (channel , x, y) -> x, y, 3\n",
        "\n",
        "print(x.shape)\n",
        "\n",
        "fig, axs = plt.subplots(2,2)\n",
        "\n",
        "axs = axs.flatten()\n",
        "\n",
        "# Add tracers, 5x5 patch every 100\n",
        "\n",
        "rows = torch.arange(x.shape[0]) % 100 < 100\n",
        "cols = torch.arange(x.shape[1]) % 100 < 5\n",
        "mask = rows.unsqueeze(-1) & cols.unsqueeze(-1).T\n",
        "\n",
        "# Dim image\n",
        "x = x * 0.7\n",
        "\n",
        "# Dots to gradient\n",
        "\n",
        "l = torch.linspace(0, 1, mask.sum())\n",
        "\n",
        "gradient = torch.zeros((mask.sum(), 3))\n",
        "\n",
        "gradient[:, 0] = 1\n",
        "gradient[:, 1] = l\n",
        "gradient[:, 2] = 0\n",
        "\n",
        "x[mask] = gradient\n",
        "\n",
        "print(x.stride())\n",
        "print(x.view(-1, 375, 3).stride())\n",
        "\n",
        "# axs[0].imshow(x)\n",
        "# axs[1].imshow(x.transpose(0,1))\n",
        "# axs[2].imshow(x.max()- x)\n",
        "axs[0].imshow(x.view((-1, 375, 3)))\n",
        "axs[1].imshow(x.view((-1, 800, 3)))\n",
        "axs[2].imshow(x.view((-1, 1200, 3)))\n",
        "axs[3].imshow(x.view((-1, 2000, 3)))"
      ],
      "metadata": {
        "id": "8FlBrAQkxzvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = torch.randn((28,28,1), dtype=torch.float)\n",
        "\n",
        "# Max and min\n",
        "print(\n",
        "    f\"Min {img.min()} at {img.argmin()} | {img.flatten()[img.argmin()]}\",\n",
        "    f\"Max {img.max()} at {img.argmax()} | {img.flatten()[img.argmax()]}\",\n",
        "    f\"Arg sort top 5 {img.flatten().argsort()[:5]}\",\n",
        "    f\"Sort value top 5 {img.flatten().topk(5).values}\",\n",
        "    sep='\\n',\n",
        ")\n",
        "\n",
        "# Get indicies of mask\n",
        "mask = img.abs() > 2.5 # 2.5 stds\n",
        "\n",
        "print(\n",
        "    mask.argwhere()\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"Any pixels > 3 stds?:\", (img.abs() > 3).any().item()\n",
        ")\n",
        "\n",
        "fig, axs = plt.subplots(1, 2)\n",
        "\n",
        "axs = axs.flatten()\n",
        "\n",
        "axs[0].imshow(img, cmap='gray')\n",
        "\n",
        "img[~mask] = 0\n",
        "\n",
        "axs[1].imshow(img, cmap='gray')"
      ],
      "metadata": {
        "id": "VwUapOARDQOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensures everything is reproducable, ChatGPT\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "seed = 42\n",
        "\n",
        "random.seed(seed)  # Pythons built-in random module\n",
        "np.random.seed(seed)  # NumPy random seed\n",
        "torch.manual_seed(seed)  # PyTorch CPU seed\n",
        "torch.cuda.manual_seed(seed)  # PyTorch CUDA seed\n",
        "torch.cuda.manual_seed_all(seed)  # All GPUs\n",
        "torch.backends.cudnn.deterministic = True  # Ensures deterministic CNN results\n",
        "torch.backends.cudnn.benchmark = False  # Disables optimization for reproducibility"
      ],
      "metadata": {
        "id": "IixQitmty9E3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Types\n",
        "\n",
        "##### **Floats**\n",
        "float16 => torch.float16 | torch.half <br>\n",
        "float32 => torch.float32 | torch.float <br>\n",
        "float64 => torch.float64 | torch.double <br>\n",
        "\n",
        "##### **Ints**\n",
        "uint8 => torch.uint8 @depricated <br>\n",
        "int8 => torch.int8 <br>\n",
        "int16 => torch.int16 | torch.short <br>\n",
        "int32 => torch.int32 | torch.int <br>\n",
        "int64 => torch.int64 | torch.long <br>\n",
        "\n",
        "##### **Bool**\n",
        "bool => torch.bool <br>\n",
        "\n",
        "##### **Complex Numbers, two floats**\n",
        "complex64 => torch.complex64 | torch.float32 + torch.float32 <br>\n",
        "complex128 => torch.complex128 | torch.float64 + torch.float64 <br>\n",
        "\n",
        "##### **Quantization**\n",
        "qint8 => torch.qint8 <br>\n",
        "quint8 => torch.quint8 <br>\n",
        "qint32 => torch.qint32 <br>\n",
        "\n",
        "##### **Brain Floats**\n",
        "bfloat16 => torch.bfloat16 (same range as float32 less precise) <br>"
      ],
      "metadata": {
        "id": "lypRmkRvy--z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Math"
      ],
      "metadata": {
        "id": "KF_uEGy_zcYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Basic Operations"
      ],
      "metadata": {
        "id": "dSk133CNWgPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basics\n",
        "\n",
        "a = torch.randint(size=(2,2), low=0, high=10, dtype=torch.float)\n",
        "\n",
        "b = torch.ones((2,2))\n",
        "\n",
        "# Add\n",
        "\n",
        "a + b\n",
        "\n",
        "# Sub\n",
        "\n",
        "a - b\n",
        "\n",
        "# elem multi\n",
        "\n",
        "a * b\n",
        "\n",
        "# elem div\n",
        "\n",
        "a / b\n",
        "\n",
        "# Mat mul\n",
        "\n",
        "a @ b\n",
        "\n",
        "# Batch matmul, faster, shapes must be (batch, N, M) (batch, K, N)\n",
        "\n",
        "torch.bmm(\n",
        "    torch.randn(10, 4, 5),\n",
        "    torch.randn(10, 5, 4),\n",
        ")\n",
        "\n",
        "# mm then add, for linear layer, faster on gpu\n",
        "\n",
        "torch.addmm(\n",
        "    torch.randn(10, 10), # Bias\n",
        "    torch.randn(10, 5), # Weights\n",
        "    torch.randn(5, 10), # Inputs\n",
        ")\n",
        "\n",
        "# Absolute\n",
        "a.abs()\n",
        "\n",
        "# Square\n",
        "a ** 2\n",
        "\n",
        "# Sqrt\n",
        "a.sqrt()\n",
        "\n",
        "# Exponential (e^a)\n",
        "a.exp()\n",
        "\n",
        "# Natural logarithm, ln\n",
        "a.log()\n",
        "\n",
        "# Log 10\n",
        "a.log10()\n",
        "\n",
        "# Stats\n",
        "\n",
        "# Sum\n",
        "a.sum()\n",
        "\n",
        "# Mean / median / mode\n",
        "a.mean()\n",
        "a.median()\n",
        "a.mode()\n",
        "\n",
        "# std / var / quantiles\n",
        "a.std()\n",
        "a.var()\n",
        "a.quantile(0.75)\n",
        "\n",
        "# Extremes\n",
        "a.min()\n",
        "a.max()\n",
        "\n",
        "# Values to [min, max]\n",
        "a.clamp(0,1)\n",
        "\n",
        "# Position of max / min\n",
        "a.argmax()\n",
        "a.argmin()\n",
        "\n",
        "# Get number of non-zero elements\n",
        "a.count_nonzero()\n",
        "\n",
        "# Sort, returns (values=[...], indices=[...])\n",
        "\n",
        "# Get top k items, returns (values=[...], indices=[...])\n",
        "a.flatten().topk(3)\n",
        "\n",
        "# Binning, equal size between min and max, else data min and max\n",
        "a.histc(4)\n",
        "\n",
        "# PDF, dim key word, return in size of dim use compress on other dims\n",
        "b.flatten().cumsum(dim=-1)\n",
        "\n",
        "# Get unique\n",
        "b.unique(return_counts=True)\n",
        "\n",
        "pass"
      ],
      "metadata": {
        "id": "eCej6x3lWjne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Benchmarking mm vs bmm, would only matter on very large batches, mm detected batches now\n",
        "\n",
        "b: int = int(1e4)\n",
        "\n",
        "a, b = torch.randn(b, 100, 100), torch.randn(b, 100, 100)\n",
        "\n",
        "%timeit torch.matmul(a, b)\n",
        "%timeit torch.bmm(a, b)\n",
        "\n",
        "pass"
      ],
      "metadata": {
        "id": "4_uu-d43sLoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Linalg"
      ],
      "metadata": {
        "id": "PNI49JaMW2g1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randint(size=(3,3), low=0, high=6, dtype=torch.float)\n",
        "\n",
        "b = torch.randint(size=(3,), low=0, high=6, dtype=torch.float)\n",
        "\n",
        "# diagonal\n",
        "\n",
        "a.diag()\n",
        "\n",
        "# trace, sum diag\n",
        "\n",
        "a.trace()\n",
        "\n",
        "# Get rank\n",
        "\n",
        "torch.linalg.matrix_rank(a)\n",
        "\n",
        "# Get determinant\n",
        "\n",
        "assert a.det() != 0, \"Matrix is singular\"\n",
        "\n",
        "# Numerically stable log determinant, for large matrix\n",
        "sign, abslogdet = torch.linalg.slogdet(a)\n",
        "# a = sign * exp(abslogdet)\n",
        "\n",
        "# Norm\n",
        "\n",
        "# L1\n",
        "torch.linalg.norm(b, ord=1)\n",
        "\n",
        "# L2\n",
        "torch.linalg.norm(b, ord=2)\n",
        "\n",
        "# L any p, sum(i ** p) ** 1/p\n",
        "p: int = 9\n",
        "torch.linalg.norm(b, ord=p)\n",
        "\n",
        "# inverse\n",
        "\n",
        "a.inverse()\n",
        "\n",
        "# rref, through lu\n",
        "\n",
        "P, L, U = torch.lu_unpack(\n",
        "    *torch.linalg.lu_factor(a)\n",
        ")\n",
        "\n",
        "\n",
        "# QR decomp\n",
        "Q, R = torch.linalg.qr(a)\n",
        "\n",
        "# Eigen, returns complex\n",
        "eigenvalues, eigenvectors = torch.linalg.eig(a)\n",
        "eigvals_real = torch.linalg.eigvalsh(a)\n",
        "\n",
        "# Matrix SVD\n",
        "U, S, V = torch.linalg.svd(a)\n",
        "\n",
        "# Solving linear system, a must be square\n",
        "torch.linalg.solve(a, b)\n",
        "\n",
        "# Solve least square solution, rows > columns -> projection, columns > rows min norm\n",
        "torch.linalg.lstsq(a, b)\n",
        "# In this case same as solve\n",
        "\n",
        "# element wise aii * a (k, m) (q, n) -> (kq, mn)\n",
        "torch.kron(a, a)\n",
        "\n",
        "pass"
      ],
      "metadata": {
        "id": "IozUNjokW8dI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Autograd"
      ],
      "metadata": {
        "id": "I24G-3-V2yaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the gradient of a variable with respect to another variable\n",
        "# Tracks operations using a graph\n",
        "\n",
        "a = torch.tensor(2.0, requires_grad=True)\n",
        "\n",
        "loss = (a - 4) ** 2\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print(a.grad)\n",
        "\n",
        "# remove history\n",
        "a.grad.zero_()\n",
        "\n",
        "print(a.grad)"
      ],
      "metadata": {
        "id": "Edg8by4W21xV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Not using grad\n",
        "\n",
        "with torch.no_grad():\n",
        "  pass"
      ],
      "metadata": {
        "id": "sido8W0MNU1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple training loop\n",
        "\n",
        "from itertools import repeat\n",
        "\n",
        "a = torch.tensor(torch.randint(size=(1,), low=-100, high=100, dtype=torch.float).item(), requires_grad=True)\n",
        "\n",
        "# Optimal solution is 4\n",
        "loss_fn = lambda x: (x - 4) ** 2\n",
        "\n",
        "epochs: int = 500\n",
        "lr: float = 1e-2\n",
        "\n",
        "# Track\n",
        "loss_hist = []\n",
        "a_hist = []\n",
        "\n",
        "for _ in repeat(None, epochs):\n",
        "\n",
        "  loss = loss_fn(a)\n",
        "\n",
        "  loss_hist.append(loss.item())\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  # print(\n",
        "  #     f\"A ({a.item()} -> {a.item() - lr * a.grad.item()})\",\n",
        "  #     f\"Loss: {loss.item()}\",\n",
        "  #     f\"Grad: {a.grad.item()}\",\n",
        "  #     \"\",\n",
        "  #     sep='\\n'\n",
        "  # )\n",
        "\n",
        "  a = torch.tensor(float(a.item() - lr * a.grad.item()), requires_grad=True)\n",
        "\n",
        "  a_hist.append(a.item())\n",
        "\n",
        "  if a.grad: a.grad.zero_()\n",
        "\n",
        "plt.plot(range(epochs), loss_hist)\n",
        "plt.plot(range(epochs), a_hist, 'r')\n",
        "plt.plot(range(epochs), list(repeat(4, epochs)), 'b--')"
      ],
      "metadata": {
        "id": "B0SWfDr9FpDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Networks\n",
        "\n",
        "- Dataloaders\n",
        "- Linear Model (Fibonnaci)\n",
        "- Linear Model (MNIST)\n",
        "- RNN Model (IMDB)"
      ],
      "metadata": {
        "id": "WHFhSX8SKiU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
        "from torch import optim, nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets as vdatasets\n",
        "\n",
        "from torchvision.datasets import MNIST, CIFAR10\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "a9bV4kKKNWzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataloaders"
      ],
      "metadata": {
        "id": "kSMt2cS9Ks02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model on fibonnaci, test for generalization, it wont lol\n",
        "\n",
        "x = torch.arange(0, 30, 1)\n",
        "\n",
        "y = torch.tensor(list(map(fibbonaci, x)))\n",
        "\n",
        "p = torch.randperm(x.shape[0])\n",
        "\n",
        "x, y = x[p], y[p]\n",
        "\n",
        "cutoff: int = 25\n",
        "\n",
        "x_train, y_train, x_test, y_test = x[:cutoff], y[:cutoff], x[cutoff:], y[cutoff:]\n",
        "\n",
        "# Validate on 30 - 40\n",
        "\n",
        "x_val = torch.arange(30, 40, 1)\n",
        "\n",
        "y_val = torch.tensor(list(map(fibbonaci, x_val)))"
      ],
      "metadata": {
        "id": "OHQ7_tHZQdPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataset\n",
        "\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class FibbonaciSet(Dataset):\n",
        "\n",
        "  def __init__(self, x, y):\n",
        "\n",
        "    self.x = x.to(torch.double)\n",
        "\n",
        "    # Log for numerical stability\n",
        "    self.y = y.to(torch.double).log()\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "\n",
        "    return self.x.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx: int) -> Tuple[torch.long, torch.long]:\n",
        "\n",
        "    return self.x[idx], self.y[idx]\n",
        "\n",
        "train = FibbonaciSet(x_train, y_train)\n",
        "test = FibbonaciSet(x_test, y_test)\n",
        "val = FibbonaciSet(x_val, y_val)\n",
        "\n",
        "# indexing (x, y)\n",
        "train[0:3]\n",
        "\n",
        "# iterating\n",
        "for x, y in train:\n",
        "  break\n",
        "\n",
        "# Concat datasets\n",
        "unseen = ConcatDataset([test, val])\n",
        "\n",
        "pass"
      ],
      "metadata": {
        "id": "FKDMsE3Dg_LJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloaders\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train,\n",
        "    batch_size=4,\n",
        "    shuffle=True,\n",
        "    num_workers=2, # <-- For computation\n",
        "    pin_memory=False, # <-- For GPU things\n",
        "    drop_last=False, # <-- For incomplete batches\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test,\n",
        "    batch_size=4,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=False,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val,\n",
        "    batch_size=4,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=False,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "# iterating\n",
        "for x, y in train_loader:\n",
        "  break\n",
        "\n",
        "# Does not support indexing\n",
        "try:\n",
        "  train_loader[0]\n",
        "except TypeError as TE:\n",
        "  print(\"Does not\")"
      ],
      "metadata": {
        "id": "dqUKzK2xKCUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Model (Fibonnaci)"
      ],
      "metadata": {
        "id": "fFe2jgaMMsfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as f\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(1, 10)\n",
        "    self.fc2 = nn.Linear(10, 10)\n",
        "    self.fc3 = nn.Linear(10, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "model = Model()\n",
        "naive_model = copy.deepcopy(model)\n",
        "model = model.to(torch.double)"
      ],
      "metadata": {
        "id": "J9CQXncAMwkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile (optional)\n",
        "\n",
        "# model = torch.compile(model)"
      ],
      "metadata": {
        "id": "pxntA__cQQpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "train_hist = []\n",
        "test_hist = []\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
        "\n",
        "epochs: int = 100\n",
        "\n",
        "for i in range(epochs):\n",
        "\n",
        "  print(\n",
        "      f\"Epoch: {i + 1}/{epochs}\"\n",
        "  )\n",
        "\n",
        "  clear_output(wait=True)\n",
        "\n",
        "  for x, y in train_loader:\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(x.unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "    loss = loss_fn(y, output)\n",
        "\n",
        "    train_hist.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  for x, y in test_loader:\n",
        "\n",
        "    test_hist.append(\n",
        "        loss_fn(\n",
        "            y, model(x.unsqueeze(-1)).squeeze(-1)\n",
        "        ).item()\n",
        "    )\n",
        "\n",
        "# go by epochs ignore batches\n",
        "plt.plot(range(epochs), train_hist[::7], 'b')\n",
        "plt.plot(range(epochs), test_hist[::2], 'r')"
      ],
      "metadata": {
        "id": "cFEJuU07QXZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in val_loader:\n",
        "  print(\n",
        "      loss_fn(\n",
        "        y, model(x.unsqueeze(-1)).squeeze(-1)\n",
        "    )\n",
        "  )"
      ],
      "metadata": {
        "id": "rdN3OrctTu48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show diffrence between naive and trained\n",
        "\n",
        "n: int = 30\n",
        "\n",
        "loss_naive = []\n",
        "loss_trained = []\n",
        "\n",
        "model.eval()\n",
        "naive_model.eval()\n",
        "\n",
        "for i in range(n):\n",
        "\n",
        "  true = fibbonaci(i)\n",
        "\n",
        "  naive = naive_model(torch.tensor(i, dtype=torch.float).unsqueeze(-1))\n",
        "  trained = model(torch.tensor(i, dtype=torch.double).unsqueeze(-1))\n",
        "\n",
        "  loss_naive.append(\n",
        "      loss_fn(\n",
        "          torch.tensor(true),\n",
        "          naive\n",
        "      ).detach().numpy()\n",
        "  )\n",
        "\n",
        "  loss_trained.append(\n",
        "      loss_fn(torch.tensor(true), trained).detach().numpy()\n",
        "  )\n",
        "\n",
        "# Loss by number for fibonnaci\n",
        "print(\"Avg MSE naive \", sum(loss_naive) / loss_naive.__len__())\n",
        "print(\"Avg MSE trained \", sum(loss_trained) / loss_trained.__len__())\n",
        "\n",
        "# This model is bad"
      ],
      "metadata": {
        "id": "mms7gqBLgOR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Model (MNIST)"
      ],
      "metadata": {
        "id": "mw7bDWqnTXhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset and Dataloader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # Between -1 and 1\n",
        "    transforms.Normalize(0.5, 0.5),\n",
        "])\n",
        "\n",
        "train_dataset = vdatasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset  = vdatasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False, pin_memory=True)"
      ],
      "metadata": {
        "id": "krlE6cB3TbX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check image distributions\n",
        "\n",
        "for x, y in train_loader:\n",
        "  img = x\n",
        "  print(img.min(), img.max(), img.mean(), img.std())\n",
        "  break"
      ],
      "metadata": {
        "id": "gutZorl0ZtcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot sample images\n",
        "\n",
        "fig, axs = plt.subplots(8,8, figsize=(14, 14))\n",
        "\n",
        "axs = axs.flatten()\n",
        "\n",
        "for x, _ in train_loader:\n",
        "\n",
        "  break\n",
        "\n",
        "for a, img in zip(axs, x):\n",
        "\n",
        "  a.imshow(img.permute(1, 2, 0), cmap='gray')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "GYfA8kqCbhdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try straight linear no featurization\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "  def __init__(self) -> None:\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(784, 128)\n",
        "    self.fc2 = nn.Linear(128, 64)\n",
        "    self.out = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, x) -> None:\n",
        "\n",
        "    x = nn.Flatten()(x)\n",
        "    x = self.fc1(x)\n",
        "    x = nn.ReLU()(x)\n",
        "    x = self.fc2(x)\n",
        "    x = nn.ReLU()(x)\n",
        "    x = self.out(x)\n",
        "\n",
        "    return x # <-- Return Logits for Categorical Cross Entropy\n",
        "\n",
        "model = Model()\n",
        "model.to(device)\n",
        "\n",
        "next(model.parameters()).device"
      ],
      "metadata": {
        "id": "AF00n0POc-E2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "epochs: int = 10\n",
        "lr: float = 1e-2\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "loss_hist = torch.zeros(size=(train_loader.__len__() * epochs,))\n",
        "\n",
        "def hist():\n",
        "  yield from [l for l in range(loss_hist.shape[0])]\n",
        "\n",
        "h = hist()\n",
        "\n",
        "for i in range(epochs):\n",
        "\n",
        "  print(f\"{i + 1}/{epochs}\")\n",
        "\n",
        "  print(\n",
        "      'Loss:',\n",
        "      loss_hist[i * train_loader.__len__() - 1].item()\n",
        "    )\n",
        "\n",
        "  for x, y in train_loader:\n",
        "\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss = loss_fn(\n",
        "        model(x),\n",
        "        y\n",
        "    )\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    loss_item = loss.detach().item()\n",
        "\n",
        "    loss_hist[next(h)] = loss_item\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  clear_output(wait=True)\n"
      ],
      "metadata": {
        "id": "jWLwogmVeHCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show smoothed graph\n",
        "\n",
        "s: int = 10\n",
        "\n",
        "conv_window = torch.ones((1,1, s)) / s\n",
        "\n",
        "smoothed_graph = F.conv1d(loss_hist.view(1, 1, -1), conv_window, padding=s//2)\n",
        "\n",
        "plt.plot(range(smoothed_graph.shape[-1]), smoothed_graph.view(-1))"
      ],
      "metadata": {
        "id": "3nfuJkAvyCSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics.classification import Accuracy\n",
        "\n",
        "metric = Accuracy(task=\"multiclass\", num_classes=10)\n",
        "metric.to(device)\n",
        "\n",
        "acc = []\n",
        "\n",
        "# During training or eval\n",
        "for x, y in test_loader:\n",
        "\n",
        "  x = x.to(device)\n",
        "  y = y.to(device)\n",
        "\n",
        "  acc.append(metric(model(x), y))\n",
        "\n",
        "sum(acc) / acc.__len__()"
      ],
      "metadata": {
        "id": "f-Y4O91ajRA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN Model (IMDB)"
      ],
      "metadata": {
        "id": "f86w_ZWj_jeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"imdb\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "cvTikUrf_pMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dist = torch.tensor(dataset['train']['label']).unique(return_counts=True)\n",
        "test_dist = torch.tensor(dataset['test']['label']).unique(return_counts=True)\n",
        "\n",
        "for dist in (train_dist, test_dist):\n",
        "\n",
        "  for label, num in zip(*dist):\n",
        "\n",
        "    print(\n",
        "        f\"Label {label} has {num} examples\"\n",
        "    )\n",
        "\n",
        "# 50/50 for both sets"
      ],
      "metadata": {
        "id": "YjYF2Xe3_zm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset and Loader\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "\n",
        "  def __init__(self, text, labels) -> None:\n",
        "\n",
        "    self.text = text\n",
        "    self.labels = labels\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "\n",
        "    return self.text.__len__()\n",
        "\n",
        "  def __getitem__(self, idx: int) -> Tuple[str, int]:\n",
        "\n",
        "    return self.text[idx], self.labels[idx]\n",
        "\n",
        "train = TextDataset(dataset['train']['text'], dataset['train']['label'])\n",
        "test = TextDataset(dataset['test']['text'], dataset['test']['label'])\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)"
      ],
      "metadata": {
        "id": "yxAeXCcsBfNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "bert.eval()\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, embedder, tokenizer):\n",
        "        super().__init__()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.embedder = embedder\n",
        "\n",
        "        self.rnn = nn.RNN(\n",
        "            input_size=768,\n",
        "            hidden_size=384,\n",
        "            num_layers=3,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(384, 192)\n",
        "        self.fc2 = nn.Linear(192, 96)\n",
        "        self.fc3 = nn.Linear(96, 32)\n",
        "        self.output = nn.Linear(32, 2)\n",
        "        self.act = nn.GELU()\n",
        "\n",
        "    def forward(self, text: str) -> torch.Tensor:\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            return_tensors='pt',\n",
        "            padding=True,\n",
        "            truncation=True\n",
        "        ).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            bert_output = self.embedder(**encoding)\n",
        "\n",
        "            x = bert_output.last_hidden_state\n",
        "\n",
        "        x, _ = self.rnn(x)\n",
        "\n",
        "        x = x[:, -1, :]\n",
        "\n",
        "        x = self.act(self.fc1(x))\n",
        "        x = self.act(self.fc2(x))\n",
        "        x = self.act(self.fc3(x))\n",
        "        x = self.output(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = Model(bert, tokenizer)\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "sr63-jubELbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "epochs = 10\n",
        "lr = 1e-2\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "loss_hist = []\n",
        "\n",
        "model.train()\n",
        "\n",
        "for e in range(epochs):\n",
        "\n",
        "  total_loss = 0\n",
        "\n",
        "  loop = tqdm(train_loader, desc=f\"Epoch {e + 1}\")\n",
        "\n",
        "  batch_num = 0\n",
        "\n",
        "  for x, y in loop:\n",
        "\n",
        "    y = y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    logits = model(x)\n",
        "\n",
        "    loss = loss_fn(logits, y)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    loss_hist.append(loss.item())\n",
        "\n",
        "    loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    batch_num += 1\n",
        "\n",
        "  print(f\"Epoch {e+1} average loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Ran out of free GPU run time :("
      ],
      "metadata": {
        "collapsed": true,
        "id": "wdcahkowTb7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")"
      ],
      "metadata": {
        "id": "GN51K6WO20Od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([], device=device)\n",
        "\n",
        "loop = tqdm(test_loader, desc=f\"Batch\")\n",
        "\n",
        "batch_num = 0\n",
        "\n",
        "for x, y in loop:\n",
        "\n",
        "  if batch_num >= 32:\n",
        "\n",
        "    break\n",
        "\n",
        "  logits = model(x).softmax(dim=0)\n",
        "\n",
        "  a = torch.concat([a, logits.argmax() == y.to(device)])\n",
        "\n",
        "  batch_num += 1"
      ],
      "metadata": {
        "id": "8muX6sSigknA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.mean()"
      ],
      "metadata": {
        "id": "SRAJXo8DjNbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(\"Hello I love this movie\")"
      ],
      "metadata": {
        "id": "HvXzkNMajyUd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}